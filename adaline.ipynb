{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "adaline.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMLllcYF2jtjdv2cwq3q5/h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jakubmis1998/NeuralNetworks/blob/main/adaline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbOlZEq7zqKp"
      },
      "source": [
        "import numpy as np\r\n",
        "from keras.datasets import mnist\r\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNQLnLtCz0dU"
      },
      "source": [
        "class Adaline():\r\n",
        "  def __init__(self, learning_rate, epochs, image_vector_size):\r\n",
        "    \"\"\"\r\n",
        "      Initialization of adaline.\r\n",
        "\r\n",
        "      Args:\r\n",
        "        learning_rate (float) - const learning rate.\r\n",
        "        epochs (integer) - learning iterations amount.\r\n",
        "        image_vector_size (integer) - single sample size.\r\n",
        "    \"\"\"\r\n",
        "    self.learning_rate = learning_rate\r\n",
        "    self.epochs = epochs\r\n",
        "    self.image_vector_size = image_vector_size\r\n",
        "    self.weights = np.random.uniform(\r\n",
        "      low = -0.0001,\r\n",
        "      high = 0.0001,\r\n",
        "      size = (10, self.image_vector_size + 1)\r\n",
        "    )\r\n",
        "\r\n",
        "  def train(self, E, C):\r\n",
        "    \"\"\"\r\n",
        "      Adaline learning based on training and expected data.\r\n",
        "\r\n",
        "      Args:\r\n",
        "        E (NumPy 2D array) - training data set.\r\n",
        "        C (NumPy 2D array) - set of correct(expected) values.\r\n",
        "    \"\"\"\r\n",
        "    for index in range(self.epochs):\r\n",
        "      # 0 - 60 000\r\n",
        "      i = np.random.randint(len(E))\r\n",
        "      # (10, 1)\r\n",
        "      O = self.predict(E[i])\r\n",
        "      # (10, 1) = (10, 60 000 i-ta kolumna) - (10, 1)\r\n",
        "      ERR = C[:, i] - O\r\n",
        "      # (10, 785) += (1, 1)             * (10, 1) * (785, 1)\r\n",
        "      self.weights += self.learning_rate * ERR.reshape(10, 1) * E[i].reshape(1, 785)\r\n",
        "  \r\n",
        "  def predict(self, sample):\r\n",
        "    \"\"\"\r\n",
        "      Checks if given data returns expected value based on the learned perceptron.\r\n",
        "\r\n",
        "      Args:\r\n",
        "        sample (NumPy array): image.\r\n",
        "    \"\"\"\r\n",
        "    return np.sum(self.weights * sample, axis = 1)\r\n",
        "  \r\n",
        "  def calculate_effeciency(self, test_data, expected_values):\r\n",
        "    \"\"\"\r\n",
        "      Calculate percentage of well-recognized numbers using test data.\r\n",
        "\r\n",
        "      Args:\r\n",
        "        test_data (NumPy array): array with test daya.\r\n",
        "        expected_values (NumPy array): expected values for test data.\r\n",
        "    \"\"\"\r\n",
        "    correct_numbers_counter = 0\r\n",
        "\r\n",
        "    for i, value in enumerate(test_data):\r\n",
        "      predictions = self.predict(value)\r\n",
        "\r\n",
        "      result = []\r\n",
        "      for j, predict_value in enumerate(predictions):\r\n",
        "        if predict_value > 0:\r\n",
        "          result.append(j)\r\n",
        "\r\n",
        "      predicted_number = result\r\n",
        "      correct_number = expected_values[i]\r\n",
        "      \r\n",
        "      if correct_number in predicted_number and len(predicted_number) == 1:\r\n",
        "        correct_numbers_counter += 1\r\n",
        "\r\n",
        "    print('{good}/{total} => {percents}%'.format(\r\n",
        "      good=correct_numbers_counter,\r\n",
        "      total=len(expected_values),\r\n",
        "      percents=round(float(correct_numbers_counter) / float(len(expected_values)) * 100.0, 2),\r\n",
        "    ))\r\n",
        "\r\n",
        "\r\n",
        "def show_image(img):\r\n",
        "  \"\"\"Show 2D image from NumPy array\"\"\"\r\n",
        "  plt.imshow(img, cmap=\"gray\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QeOWHly1L5O"
      },
      "source": [
        "# Adaline initialization\r\n",
        "adaline = Adaline(\r\n",
        "  learning_rate = 0.001,\r\n",
        "  epochs = 1000000,\r\n",
        "  image_vector_size = 28*28\r\n",
        ")\r\n",
        "\r\n",
        "# Mnist data initialization\r\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\r\n",
        "\r\n",
        "# Expected values initialization\r\n",
        "x_train_expected_values = np.array([])\r\n",
        "for i in range(10):\r\n",
        "  x_train_expected_values = np.append(\r\n",
        "    x_train_expected_values,\r\n",
        "    [1 if val == i else -1 for val in y_train]\r\n",
        "  )\r\n",
        "x_train_expected_values = x_train_expected_values.reshape(10, 60000)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEGki1z023Ui"
      },
      "source": [
        "# Flatten and norm images from training data\r\n",
        "\r\n",
        "# # 60 000 x 28*28 \r\n",
        "x_train = x_train.reshape(x_train.shape[0], adaline.image_vector_size)\r\n",
        "x_train = np.ceil(x_train / 255.0)\r\n",
        "# Add 1 in front of each row in the matrix - # 60 000 x (28*28 + 1) \r\n",
        "x_train_with_bias = np.insert(x_train, 0, 1, axis=1)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79baZzNA3Bsr"
      },
      "source": [
        "# Flatten and norm images from test data\r\n",
        "\r\n",
        "# # 10 000 x 28*28 \r\n",
        "x_test = x_test.reshape(x_test.shape[0], adaline.image_vector_size)\r\n",
        "x_test = np.ceil(x_test / 255.0)\r\n",
        "# Add 1 in front of each row in the matrix - # 10 000 x (28*28 + 1)\r\n",
        "x_test_with_bias = np.insert(x_test, 0, 1, axis=1)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ModC-CJ8Kem"
      },
      "source": [
        "# Train adaline\r\n",
        "\r\n",
        "adaline.train(x_train_with_bias, x_train_expected_values)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mgN_l9w4SBS",
        "outputId": "7e661446-78d3-4863-f0f8-79bc1f00486c"
      },
      "source": [
        "# Calculate percentage of well-recognized numbers\r\n",
        "\r\n",
        "adaline.calculate_effeciency(x_test_with_bias, y_test)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7334/10000 => 73.34%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}