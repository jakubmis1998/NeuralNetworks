{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "digitsRecognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPWft7+QMLs2BYcFPIMNvSS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jakubmis1998/NeuralNetworks/blob/main/digitsRecognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UYn6iFOg-Wy",
        "outputId": "2f3c787a-76b2-4e49-d2eb-c26a556c2834",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        }
      },
      "source": [
        "# Digits recognition\n",
        "\n",
        "import keras.preprocessing.image as kpi\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "class Perceptron():\n",
        "  def __init__(self, learning_rate, iterations, sample_dim, samples_dim):\n",
        "    \"\"\"\n",
        "      Initialization of perceptron.\n",
        "\n",
        "      Args:\n",
        "        learning_rate (float) - const learning rate.\n",
        "        iterations (integer) - learning iterations amount.\n",
        "        sample_dim ((integer, integer)) - single sample dimensions.\n",
        "        samples_dim ((integer, integer)) - all samples dimensions.\n",
        "    \"\"\"\n",
        "    self.learning_rate = learning_rate\n",
        "    self.iterations = iterations\n",
        "    self.sample_dim = sample_dim\n",
        "    self.samples_dim = samples_dim\n",
        "    # Random THETA [-1, 1)\n",
        "    self.THETA = np.random.default_rng().uniform(-1, 1, 1)[0]\n",
        "    # Random weights [-1, 1)\n",
        "    self.weights = np.random.default_rng().uniform(-1, 1, self.sample_dim)\n",
        "  \n",
        "  def train(self, training_data, expected_values):\n",
        "    \"\"\"\n",
        "      Perceptron learning based on training and expected data.\n",
        "\n",
        "      Args:\n",
        "        training_data (NumPy 2D array) - training data set.\n",
        "        expected_values (NumPy 2D array) - set of correct(expected) values.\n",
        "    \"\"\"\n",
        "    global_life_time = 0\n",
        "    local_life_time = 0\n",
        "    global_classified_number = 0\n",
        "    local_classified_number = 0\n",
        "    classified = np.full((self.samples_dim[0], self.samples_dim[1]), False)\n",
        "    best_weights = self.weights\n",
        "\n",
        "    for index in range(self.iterations):\n",
        "      # Coordinates of random digit\n",
        "      i = np.random.randint(self.samples_dim[0])  # Row\n",
        "      j = np.random.randint(self.samples_dim[1])  # Column\n",
        "\n",
        "      # Predict\n",
        "      ERR = self.predict(training_data[i][j], expected_values[i][j])\n",
        "\n",
        "      # Unclassified sample\n",
        "      if ERR != 0:\n",
        "        # Reset local life time and number of classified samples\n",
        "        local_life_time = 0\n",
        "        local_classified_number = 0\n",
        "        # Reset classified samples\n",
        "        classified = np.full((self.samples_dim[0], self.samples_dim[1]), False)\n",
        "        # Weights and THETA calculate\n",
        "        self.weights += self.learning_rate * ERR * training_data[i][j]\n",
        "        self.THETA -= self.learning_rate * ERR\n",
        "      # Classified sample\n",
        "      else:\n",
        "        # Increase life time\n",
        "        local_life_time += 1\n",
        "        # Classify sample if not processed yet\n",
        "        if not classified[i][j]:\n",
        "          classified[i][j] = True\n",
        "          local_classified_number += 1\n",
        "        # Store current winner and set new better weights\n",
        "        if global_life_time < local_life_time and global_classified_number < local_classified_number:\n",
        "          global_life_time = local_life_time\n",
        "          global_classified_number = local_classified_number\n",
        "          best_weights = self.weights.copy()\n",
        "    \n",
        "    # Set the best weights for perceptron\n",
        "    self.weights = best_weights\n",
        "\n",
        "  def predict(self, digit, expected_value):\n",
        "    \"\"\"\n",
        "      Checks if given data returns expected value based on the learned perceptron.\n",
        "\n",
        "      Args:\n",
        "        digit (NumPy array): Digit.\n",
        "        expected_value (number): 0(No) / 1(Yes).\n",
        "    \"\"\"\n",
        "    O = 1 if np.dot(self.weights.flatten(), digit.flatten()) - self.THETA >= 0 else -1\n",
        "    ERR = expected_value - O\n",
        "    return ERR\n",
        "  \n",
        "  def calculate_efficiency(self, all_digits, digit):\n",
        "    \"\"\"\n",
        "      Returns efficiency of perceptron in %.\n",
        "\n",
        "      Args:\n",
        "        all_digits (NumPy array): All of the digits.\n",
        "        digit (number): Digit to recognize.\n",
        "    \"\"\"\n",
        "    samples_number = 1.0\n",
        "    correctly_classified = 0.0\n",
        "    # Calculate number of all samples\n",
        "    for dim in self.samples_dim:\n",
        "      samples_number *= dim\n",
        "    \n",
        "    for i in range(self.samples_dim[0]):\n",
        "      for j in range(self.samples_dim[1]):\n",
        "        # **digit** Recognition\n",
        "        if i == digit:\n",
        "          if self.predict(all_digits[i][j], 1) == 0:\n",
        "            correctly_classified += 1\n",
        "        else:\n",
        "          if self.predict(all_digits[i][j], -1) == 0:\n",
        "            correctly_classified += 1\n",
        "\n",
        "    return correctly_classified / samples_number * 100\n",
        "\n",
        "  def recognize_digit(self, digit):\n",
        "    \"\"\"\n",
        "      Returns if perceptron recognizes given digit.\n",
        "\n",
        "      Args:\n",
        "        digit (NumPy array): Digit to recognize as an NumPy array.\n",
        "    \"\"\"\n",
        "    return \"That's my digit\" if self.predict(digit, 1) == 0 else \"---\"\n",
        "\n",
        "  def split_into_2D(self, image_name):\n",
        "    # 2D array with single pictures\n",
        "    array_2D = np.array([])\n",
        "\n",
        "    # Load the main image\n",
        "    main_img = kpi.load_img(image_name)\n",
        "\n",
        "    # Convert to numpy array\n",
        "    all_images = kpi.img_to_array(main_img)  # RGB 0-255 values\n",
        "    all_images /= 255  # RGB 0-1 values\n",
        "\n",
        "    # Split entire array with all digits to single images\n",
        "    for i in range(self.samples_dim[0]):\n",
        "      row = np.array([])\n",
        "      for j in range(self.samples_dim[1]):\n",
        "        # Create single 7x5 and remove last RGB canal\n",
        "        single_image = all_images[\n",
        "          i*self.sample_dim[0]:(i+1)*self.sample_dim[0],\n",
        "          j*self.sample_dim[1]:(j+1)*self.sample_dim[1]\n",
        "        ][:, :, 0]\n",
        "        # Append single 7x5 picture\n",
        "        row = np.append(row, single_image)\n",
        "      # Append 8 pictures (row of 7x5 single pictures)\n",
        "      array_2D = np.append(array_2D, row)\n",
        "    \n",
        "    # Make 2D array with 7x5 pictures\n",
        "    array_2D = array_2D.reshape(\n",
        "      self.samples_dim[0],\n",
        "      self.samples_dim[1],\n",
        "      self.sample_dim[0],\n",
        "      self.sample_dim[1]\n",
        "    )\n",
        "    print(\"Single image shape:\", array_2D[0][0].shape)\n",
        "    print(\"Row shape:\", array_2D[0].shape)\n",
        "    print(\"Array shape:\", array_2D.shape)\n",
        "    print(\"Samples number:\", array_2D.size // (self.sample_dim[0] * self.sample_dim[1]))\n",
        "    print(\"\\n\")\n",
        "\n",
        "    return array_2D\n",
        "\n",
        "def show_image(img):\n",
        "  \"\"\"Show 2D image from NumPy array\"\"\"\n",
        "  plt.imshow(img)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  # Perceptrons initialization\n",
        "  perceptrons = []\n",
        "  for i in range(10):\n",
        "    perceptrons.append(\n",
        "      Perceptron(\n",
        "        learning_rate=0.1,\n",
        "        iterations=10000,\n",
        "        sample_dim=(7, 5),\n",
        "        samples_dim=(10, 8)\n",
        "      )\n",
        "    )\n",
        "  \n",
        "  # An 2D array of single pictures\n",
        "  images = perceptrons[0].split_into_2D('mnist.png')\n",
        "  \n",
        "  for i, perceptron in enumerate(perceptrons):\n",
        "    # 8 samples 2D of digits == i\n",
        "    A = images[i]\n",
        "    # 72 samples 2D of digits != i\n",
        "    B = np.delete(images, i, 0)\n",
        "\n",
        "    # Samples for perceptron learning\n",
        "    E = np.zeros((\n",
        "      perceptron.samples_dim[0],\n",
        "      perceptron.samples_dim[1],\n",
        "      perceptron.sample_dim[0],\n",
        "      perceptron.sample_dim[1]\n",
        "    ))  # 80 samples\n",
        "    E = B  # 72 bad samples\n",
        "    E = np.insert(E, i, A, axis=0)  # 8 good samples at i index\n",
        "\n",
        "    # True results for perceptron learning\n",
        "    T = np.zeros((perceptron.samples_dim[0], perceptron.samples_dim[1]))\n",
        "    T[:, :] = -1\n",
        "    T = np.insert(T, i, 1, axis=0)\n",
        "\n",
        "    # Train perceptron with his data and expected values\n",
        "    perceptron.train(E, T)\n",
        "\n",
        "    # Calculate perceptron efficienct running it on all samples\n",
        "    print(\"Perceptron {} efficiency: {}%\".format(i, perceptron.calculate_efficiency(E, i)))\n",
        "\n",
        "  # Digit recognition\n",
        "  print(\"\\n\")\n",
        "  digit = E[0][0]\n",
        "  for i, perceptron in enumerate(perceptrons):\n",
        "    print(\"Perceptron {}: {}\".format(i, perceptron.recognize_digit(digit)))\n",
        "  show_image(digit)\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Single image shape: (7, 5)\n",
            "Row shape: (8, 7, 5)\n",
            "Array shape: (10, 8, 7, 5)\n",
            "Samples number: 80\n",
            "\n",
            "\n",
            "Perceptron 0 efficiency: 100.0%\n",
            "Perceptron 1 efficiency: 100.0%\n",
            "Perceptron 2 efficiency: 100.0%\n",
            "Perceptron 3 efficiency: 100.0%\n",
            "Perceptron 4 efficiency: 100.0%\n",
            "Perceptron 5 efficiency: 100.0%\n",
            "Perceptron 6 efficiency: 100.0%\n",
            "Perceptron 7 efficiency: 100.0%\n",
            "Perceptron 8 efficiency: 100.0%\n",
            "Perceptron 9 efficiency: 100.0%\n",
            "\n",
            "\n",
            "Perceptron 0: That's my digit\n",
            "Perceptron 1: ---\n",
            "Perceptron 2: ---\n",
            "Perceptron 3: ---\n",
            "Perceptron 4: ---\n",
            "Perceptron 5: ---\n",
            "Perceptron 6: ---\n",
            "Perceptron 7: ---\n",
            "Perceptron 8: ---\n",
            "Perceptron 9: ---\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rKrzdf04glM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}