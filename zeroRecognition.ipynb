{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "zeroRecognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMjFE1EOvlPM+5qv/u9I4vc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jakubmis1998/NeuralNetworks/blob/main/zeroRecognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_sfjOjPB_wr",
        "outputId": "068cf83a-ecba-466d-ced0-2d2117af2836",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "# 0 recognition\n",
        "\n",
        "import keras.preprocessing.image as kpi\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "class Perceptron():\n",
        "  def __init__(self, learning_rate, iterations, sample_dim, samples_dim):\n",
        "    \"\"\"\n",
        "      Initialization of perceptron.\n",
        "\n",
        "      Args:\n",
        "        learning_rate (float) - const learning rate.\n",
        "        iterations (integer) - learning iterations amount.\n",
        "        sample_dim ((integer, integer)) - single sample dimensions.\n",
        "        samples_dim ((integer, integer)) - samples dimensions.\n",
        "    \"\"\"\n",
        "    self.learning_rate = learning_rate\n",
        "    self.iterations = iterations\n",
        "    self.sample_dim = sample_dim\n",
        "    self.samples_dim = samples_dim\n",
        "    # Random THETA [-1, 1)\n",
        "    self.THETA = np.random.default_rng().uniform(-1, 1, 1)[0]\n",
        "    # Random weights [-1, 1)\n",
        "    self.weights = np.random.default_rng().uniform(-1, 1, self.sample_dim)\n",
        "  \n",
        "  def train(self, training_data, expected_values):\n",
        "    \"\"\"\n",
        "      Perceptron learning based on training and expected data.\n",
        "\n",
        "      Args:\n",
        "        train_data (NumPy 2D array) - training data set.\n",
        "        expected_values (NumPy 2D array) - set of correct(expected) values.\n",
        "    \"\"\"\n",
        "    global_life_time = 0\n",
        "    local_life_time = 0\n",
        "    classified = np.full((self.samples_dim[0], self.samples_dim[1]), False)\n",
        "    best_weights = self.weights\n",
        "\n",
        "    for index in range(self.iterations):\n",
        "      # Coordinates of random digit\n",
        "      i = np.random.randint(self.sample_dim[0])  # Row\n",
        "      j = np.random.randint(self.sample_dim[1])  # Column\n",
        "\n",
        "      # Predict\n",
        "      ERR = self.predict(training_data[i][j], expected_values[i][j])\n",
        "\n",
        "      # Unclassified sample\n",
        "      if ERR != 0:\n",
        "        # Reset local life time\n",
        "        local_life_time = 0\n",
        "        # Reset classified samples\n",
        "        classified = np.full((self.samples_dim[0], self.samples_dim[1]), False)\n",
        "        # Weights and THETA calculate\n",
        "        self.weights += learning_rate * ERR * training_data[i][j]\n",
        "        self.THETA -= learning_rate * ERR\n",
        "      # Classified sample\n",
        "      else:\n",
        "        # Increase life time\n",
        "        local_life_time += 1\n",
        "        # Classify sample\n",
        "        classified[i][j] = True\n",
        "        # Store current winner and set new better weights\n",
        "        if global_life_time < local_life_time:\n",
        "          global_life_time = local_life_time\n",
        "          best_weights = self.weights\n",
        "    \n",
        "    # Set the best weights for perceptron\n",
        "    self.weights = best_weights\n",
        "\n",
        "  def predict(self, digit, expected_value):\n",
        "    \"\"\"\n",
        "      Checks if given data returns expected value based on the learned perceptron.\n",
        "\n",
        "      Args:\n",
        "        digit (NumPy array): Digit.\n",
        "        expected_value (number): 0(No) / 1(Yes).\n",
        "    \"\"\"\n",
        "    O = 1 if np.dot(self.weights.flatten(), digit.flatten()) - self.THETA >= 0 else -1\n",
        "    ERR = expected_value - O\n",
        "    return ERR\n",
        "  \n",
        "  def calculate_efficiency(self, all_digits):\n",
        "    \"\"\"\n",
        "      Returns efficiency of perceptron in %.\n",
        "\n",
        "      Args:\n",
        "        all_digits (NumPy array): All of the digits.\n",
        "    \"\"\"\n",
        "    samples_number = 1.0\n",
        "    correctly_classified = 0.0\n",
        "    # Calculate all samples number\n",
        "    for dim in self.samples_dim:\n",
        "      samples_number *= dim\n",
        "\n",
        "    for i in range(self.samples_dim[0]):\n",
        "      for j in range(self.samples_dim[1]):\n",
        "        # 0 Recognition\n",
        "        if i == 0:\n",
        "          if perceptron.predict(all_digits[i][j], 1) == 0:\n",
        "            correctly_classified += 1\n",
        "        else:\n",
        "          if perceptron.predict(all_digits[i][j], -1) == 0:\n",
        "            correctly_classified += 1\n",
        "\n",
        "    return \"Perceptron efficiency: {}%\".format(correctly_classified / samples_number * 100)\n",
        "\n",
        "  def split_into_2D(self, image_name):\n",
        "    # 2D array with single pictures\n",
        "    array_2D = np.array([])\n",
        "\n",
        "    # Load the main image\n",
        "    main_img = kpi.load_img(image_name)\n",
        "\n",
        "    # Convert to numpy array\n",
        "    all_images = kpi.img_to_array(main_img)  # RGB 0-255 values\n",
        "    all_images /= 255  # RGB 0-1 values\n",
        "\n",
        "    # Split entire array with all digits to single images\n",
        "    for i in range(self.samples_dim[0]):\n",
        "      row = np.array([])\n",
        "      for j in range(self.samples_dim[1]):\n",
        "        # Create single 7x5 and remove last RGB canal\n",
        "        single_image = all_images[\n",
        "          i*self.sample_dim[0]:(i+1)*self.sample_dim[0],\n",
        "          j*self.sample_dim[1]:(j+1)*self.sample_dim[1]\n",
        "        ][:, :, 0]\n",
        "        # Append single 7x5 picture\n",
        "        row = np.append(row, single_image)\n",
        "      # Append 8 pictures (row of 7x5 single pictures)\n",
        "      array_2D = np.append(array_2D, row)\n",
        "    \n",
        "    # Make 2D array with 7x5 pictures\n",
        "    array_2D = array_2D.reshape(\n",
        "      self.samples_dim[0],\n",
        "      self.samples_dim[1],\n",
        "      self.sample_dim[0],\n",
        "      self.sample_dim[1]\n",
        "    )\n",
        "    print(\"Single image shape:\", array_2D[0][0].shape)\n",
        "    print(\"Row shape:\", array_2D[0].shape)\n",
        "    print(\"Array shape:\", array_2D.shape)\n",
        "    print(\"Samples number:\", array_2D.size // (self.sample_dim[0] * self.sample_dim[1]))\n",
        "\n",
        "    return array_2D\n",
        "\n",
        "def show_image(img):\n",
        "  \"\"\"Show 2D image from NumPy array\"\"\"\n",
        "  plt.imshow(img)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  # Perceptron initialization\n",
        "  perceptron = Perceptron(\n",
        "    learning_rate=0.1,\n",
        "    iterations=5000,\n",
        "    sample_dim=(7, 5),\n",
        "    samples_dim=(10, 8)\n",
        "  )\n",
        "\n",
        "  # An 2D array of single pictures\n",
        "  images = perceptron.split_into_2D('mnist.png')\n",
        "\n",
        "  # 8 samples 2D of digits == 0\n",
        "  A = images[0]\n",
        "  # 72 samples 2D of digits != 0\n",
        "  B = images[1:10]\n",
        "\n",
        "  # Samples for perceptron learning\n",
        "  E = np.zeros((\n",
        "    perceptron.samples_dim[0],\n",
        "    perceptron.samples_dim[1],\n",
        "    perceptron.sample_dim[0],\n",
        "    perceptron.sample_dim[1])\n",
        "  )  # 80 samples\n",
        "  E[0] = A  # 8 good samples\n",
        "  E[1:10] = B  # 72 bad samples\n",
        "\n",
        "  # True results for perceptron learning\n",
        "  T = np.zeros((perceptron.samples_dim[0], perceptron.samples_dim[1]))\n",
        "  T[0] = 1\n",
        "  T[1:10] = -1\n",
        "\n",
        "  # Train perceptron with data and expected values\n",
        "  perceptron.train(E, T)\n",
        "\n",
        "  # Calculate perceptron efficienct running it on all samples\n",
        "  print(perceptron.calculate_efficiency(E))\n",
        "\n"
      ],
      "execution_count": 389,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Single image shape: (7, 5)\n",
            "Row shape: (8, 7, 5)\n",
            "Array shape: (10, 8, 7, 5)\n",
            "Samples number: 80\n",
            "Perceptron efficiency: 95.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYydy7BH1R_4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}